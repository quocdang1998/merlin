// Copyright 2023 quocdang1998
#include "merlin/candy/model.hpp"

#include <algorithm>  // std::all_of

#include "merlin/utils.hpp"  // merlin::ptr_to_subsequence

namespace merlin {

// Evaluate result of the model at a given index
__cuhostdev__ double candy::Model::eval(const Index & index) const noexcept {
    double result = 0.0;
    for (std::uint64_t r = 0; r < this->rank_; r++) {
        double rank_eval = 1.0;
        for (std::uint64_t i_dim = 0; i_dim < this->ndim_; i_dim++) {
            rank_eval *= this->get(i_dim, index[i_dim], r);
        }
        result += rank_eval;
    }
    return result;
}

// Check if these is a negative parameter in the model
__cuhostdev__ bool candy::Model::all_positive(void) const noexcept {
    return std::all_of(this->parameters_.cbegin(), this->parameters_.cend(),
                       [](const double & value) { return value >= 0; });
}

#ifdef __NVCC__

// Copy to shared memory by CUDA block
__cudevice__ void * candy::Model::copy_by_block(candy::Model * dest_ptr, void * parameters_data_ptr,
                                                std::uint64_t thread_idx, std::uint64_t block_size) const {
    // shallow copy of data pointer
    double * parameters_data = reinterpret_cast<double *>(parameters_data_ptr);
    if (thread_idx == 0) {
        dest_ptr->parameters_.data() = parameters_data;
        dest_ptr->parameters_.size() = this->num_params();
        dest_ptr->rank_ = this->rank_;
        dest_ptr->ndim_ = this->ndim_;
    }
    __syncthreads();
    // copy data of grid nodes and grid shape
    std::uint64_t num_params = this->num_params(), ndim = this->ndim();
    for (std::uint64_t i_param = thread_idx; i_param < num_params; i_param += block_size) {
        dest_ptr->parameters_[i_param] = this->parameters_[i_param];
    }
    __syncthreads();
    for (std::uint64_t i_dim = thread_idx; i_dim < ndim; i_dim += block_size) {
        dest_ptr->rshape_[i_dim] = this->rshape_[i_dim];
    }
    __syncthreads();
    // re-calculate grid vectors
    if (thread_idx == 0) {
        ptr_to_subsequence(parameters_data, dest_ptr->rshape_.data(), ndim_, dest_ptr->param_vectors_.data());
    }
    __syncthreads();
    return reinterpret_cast<void *>(parameters_data + num_params);
}

// Copy to shared memory by CUDA thread
__cudevice__ void * candy::Model::copy_by_thread(candy::Model * dest_ptr, void * parameters_data_ptr) const {
    // shallow copy of grid node, grid shape and grid vectors
    double * parameters_data = reinterpret_cast<double *>(parameters_data_ptr);
    dest_ptr->parameters_.data() = parameters_data;
    dest_ptr->parameters_.size() = this->num_params();
    dest_ptr->rank_ = this->rank_;
    dest_ptr->ndim_ = this->ndim_;
    // copy data of grid nodes and grid shape
    std::uint64_t num_params = this->num_params(), ndim = this->ndim();
    for (std::uint64_t i_param = 0; i_param < num_params; i_param++) {
        dest_ptr->parameters_[i_param] = this->parameters_[i_param];
    }
    for (std::uint64_t i_dim = 0; i_dim < ndim; i_dim++) {
        dest_ptr->rshape_[i_dim] = this->rshape_[i_dim];
    }
    // re-calculate grid vectors
    ptr_to_subsequence(parameters_data, dest_ptr->rshape_.data(), ndim, dest_ptr->param_vectors_.data());
    return reinterpret_cast<void *>(parameters_data + num_params);
}

#endif  // __NVCC__

}  // namespace merlin
