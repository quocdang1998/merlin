// Copyright 2023 quocdang1998
#include "merlin/candy/trainer.hpp"

#include "merlin/candy/loss.hpp"  // merlin::candy::rmse_gpu
#include "merlin/cuda/event.hpp"  // merlin::cuda::Event

namespace merlin {

// ---------------------------------------------------------------------------------------------------------------------
// Utility
// ---------------------------------------------------------------------------------------------------------------------

// Train a model using GPU parallelism
void candy::train_by_gpu(candy::Model * p_model, array::Parcel * p_data, candy::Optimizer * p_optimizer,
                         candy::TrainMetric metric, std::uint64_t rep, std::uint64_t n_threads, std::uint64_t ndim,
                         const std::function<bool(double, double)> & stop_condition, std::uint64_t shared_mem_size,
                         cuda::Stream & stream) {
    // add memory for cache
    std::uint64_t total_shared_mem = shared_mem_size + n_threads * ndim;

    // calculate based on error
    double priori_error = 0.0;
    double posteriori_error = candy::rmse_gpu(p_model, p_data, ndim, shared_mem_size, n_threads);
    do {
        priori_error = posteriori_error;

        posteriori_error = candy::rmse_gpu(p_model, p_data, ndim, shared_mem_size, n_threads);
    } while (stop_condition(priori_error, posteriori_error));
}

}  // namespace merlin
