// Copyright 2023 quocdang1998
#include "merlin/candy/optmz/grad_descent.hpp"

#include "merlin/candy/model.hpp"  // merlin::candy::Model

namespace merlin {

// --------------------------------------------------------------------------------------------------------------------
// GradDescent
// --------------------------------------------------------------------------------------------------------------------

#ifdef __NVCC__

// Update model by gradient value of current thread
__cudevice__ void candy::optmz::GradDescent::update_gpu(candy::Model * p_model, floatvec * p_gradient,
                                                        void * share_ptr, std::uint64_t thread_idx,
                                                        std::uint64_t block_size) noexcept {
    double learning_rate = *(reinterpret_cast<double *>(share_ptr));
    for (std::uint64_t i_param = thread_idx; i_param < p_gradient->size(); i_param += block_size) {
        double & param = (*p_model)[i_param];
        param -= learning_rate * (*p_gradient)[i_param];
    }
    __syncthreads();
}

// Copy data to a pre-allocated memory region by a GPU block of threads
__cudevice__ void * candy::optmz::GradDescent::copy_data_by_block(void * data_ptr, std::uint64_t thread_idx,
                                                                  std::uint64_t block_size) const {
    double * learning_rate_data = reinterpret_cast<double *>(data_ptr);
    if (thread_idx == 0) {
        *learning_rate_data = this->learning_rate_;
    }
    __syncthreads();
    return reinterpret_cast<void *>(learning_rate_data + 1);
}

// Copy data to a pre-allocated memory region by a single GPU threads
__cudevice__ void * candy::optmz::GradDescent::copy_data_by_thread(void * data_ptr) const {
    double * learning_rate_data = reinterpret_cast<double *>(data_ptr);
    *learning_rate_data = this->learning_rate_;
    return reinterpret_cast<void *>(learning_rate_data + 1);
}

#endif  // __NVCC__

}  // namespace merlin
