// Copyright 2023 quocdang1998
#include "merlin/candy/loss.hpp"

#include <cinttypes>

#include "merlin/array/parcel.hpp"  // merlin::array::Parcel
#include "merlin/candy/model.hpp"  // merlin::candy::Model
#include "merlin/cuda/memory.hpp"  // merlin::cuda::Memory, merlin::cuda::copy_class_to_shared_mem
#include "merlin/utils.hpp"  // merlin::flatten_thread_index, merlin::size_of_block

namespace merlin {

// --------------------------------------------------------------------------------------------------------------------
// Loss function
// --------------------------------------------------------------------------------------------------------------------

// Calculate loss function kernel
__global__ static void calc_loss_function_kernel(const candy::Model * p_model, const array::Parcel * p_train_data,
                                                 double * p_result) {
    // get thread index
    std::uint64_t n_threads = size_of_block(), thread_idx = flatten_thread_index();
    // copy meta data to shared memory
    extern __shared__ char share_ptr[];
    auto shared_mem_tuple = cuda::copy_class_to_shared_mem(share_ptr, *p_model, *p_train_data);
    candy::Model * p_model_shared = std::get<1>(shared_mem_tuple);
    array::Parcel * p_train_data_shared = std::get<2>(shared_mem_tuple);
    std::uint64_t * cache_memory = reinterpret_cast<std::uint64_t *>(std::get<0>(shared_mem_tuple));
    double * temporary_storage = reinterpret_cast<double *>(cache_memory + n_threads * p_model->ndim());
    // initialize result array
    temporary_storage[thread_idx] = 0.0;
    // loop over each point in data
    std::uint64_t size = p_train_data->size();
    for (std::uint64_t i_point = thread_idx; i_point < size; i_point += n_threads) {
        intvec index = contiguous_to_ndim_idx(i_point, p_train_data->shape(),
                                              cache_memory + thread_idx * p_model->ndim());
        const double & point_data = (*p_train_data)[index];
        double error = (point_data == 0) ? 0.0 : (p_model->eval(index) / point_data - 1.f);
        temporary_storage[thread_idx] += error * error;
    }
    __syncthreads();
    // copy the result back to global memory
    p_result[thread_idx] = temporary_storage[thread_idx];
}

// --------------------------------------------------------------------------------------------------------------------
// Model gradient
// --------------------------------------------------------------------------------------------------------------------

// Calculate gradient of a model over dataset on GPU
__global__ static void calc_model_gradient_kernel(const candy::Model * p_model, const array::Parcel * p_train_data,
                                                  double * p_gradient) {
    // get thread index
    std::uint64_t n_threads = size_of_block(), thread_idx = flatten_thread_index();
    // copy meta data to shared memory
    extern __shared__ char share_ptr[];
    auto shared_mem_tuple = cuda::copy_class_to_shared_mem(share_ptr, *p_model, *p_train_data);
    candy::Model * p_model_shared = std::get<1>(shared_mem_tuple);
    array::Parcel * p_train_data_shared = std::get<2>(shared_mem_tuple);
    std::uint64_t * cache_memory = reinterpret_cast<std::uint64_t *>(std::get<0>(shared_mem_tuple));
    double * temporary_storage = reinterpret_cast<double *>(cache_memory + n_threads * p_model->ndim());
    // loop for each parameter
    std::uint64_t n_param = p_model->size(), n_dim = p_train_data->ndim();
    const intvec & data_shape = p_train_data->shape();
    for (std::uint64_t i_param = thread_idx; i_param < n_param; i_param += n_threads) {
        // reset shared memory
        temporary_storage[thread_idx] = 0.0;
        // get dimension, index and rank of current parameter
        auto [param_dim, param_index] = p_model->convert_contiguous(i_param);
        std::uint64_t param_rank = param_index % p_model->rank();
        param_index /= p_model->rank();
        // loop over each point in the subset of dataset related to the current parameter
        std::uint64_t n_subset = p_train_data->size() / data_shape[param_dim];
        for (std::uint64_t i_point = 0; i_point < n_subset; i_point++) {
            intvec index_data = candy::contiguous_to_ndim_idx_1(i_point, data_shape, param_dim,
                                                                cache_memory + thread_idx*n_dim);
            index_data[param_dim] = param_index;
            const double & data = (*p_train_data)[index_data];
            double gradient = 1.0;
            // divide by 1/data^2
            gradient /= (data == 0.0) ? 1.0 : data*data;
            // multiply by coefficient of the same rank from other dimension
            for (std::uint64_t i_dim = 0; i_dim < n_dim; i_dim++) {
                gradient *= (i_dim == param_dim) ? 1.0 : p_model->get(i_dim, index_data[i_dim], param_rank);
            }
            // multiply by value evaluation
            double eval = p_model->eval(index_data);
            gradient *= eval - data;
            // add gradient to gradient vector
            temporary_storage[thread_idx] += (data == 0.0) ? 0.0 : gradient;
        }
        // copy from shared memory back to global memory
        p_gradient[i_param] = temporary_storage[thread_idx];
    }
    __syncthreads();
}

// --------------------------------------------------------------------------------------------------------------------
// GPU kernel wrapper
// --------------------------------------------------------------------------------------------------------------------

// Call the GPU kernel calculation loss function on GPU
void candy::call_loss_function_kernel(const candy::Model * p_model, const array::Parcel * p_train_data,
                                      double * p_result, std::uint64_t shared_mem_size, std::uintptr_t stream_ptr,
                                      std::uint64_t n_thread) {
    ::cudaStream_t cuda_stream = reinterpret_cast<::cudaStream_t>(stream_ptr);
    calc_loss_function_kernel<<<1, n_thread, shared_mem_size, cuda_stream>>>(p_model, p_train_data, p_result);
}

// Call the GPU kernel calculating the gradient on GPU.
void candy::call_model_gradient_kernel(const candy::Model * p_model, const array::Parcel * p_train_data,
                                       double * p_gradient, std::uint64_t shared_mem_size, std::uintptr_t stream_ptr,
                                       std::uint64_t n_thread) {
    ::cudaStream_t cuda_stream = reinterpret_cast<::cudaStream_t>(stream_ptr);
    calc_model_gradient_kernel<<<1, n_thread, shared_mem_size, cuda_stream>>>(p_model, p_train_data, p_gradient);
}

}  // namespace merlin
