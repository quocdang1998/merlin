// Copyright 2024 quocdang1998
#include "merlin/regpl/regressor.hpp"

#include <algorithm>  // std::copy_n

#include "merlin/cuda/copy_helpers.hpp"  // merlin::cuda::copy_objects
#include "merlin/utils.hpp"              // merlin::flatten_thread_index, merlin::size_of_block

namespace merlin {

// ---------------------------------------------------------------------------------------------------------------------
// Utility
// ---------------------------------------------------------------------------------------------------------------------

__global__ static void eval_kernel(const regpl::Polynomial * p_poly, const double * point_data, double * p_result,
                                   std::uint64_t n_points) {
    // get thread index and block size
    std::uint64_t thread_idx = flatten_thread_index(), block_size = size_of_block();
    // copy data to shared memory
    extern __shared__ char shared_mem[];
    auto [remaining, p_poly_shr] = cuda::copy_objects(shared_mem, thread_idx, block_size, *p_poly);
    // initialize buffer
    Point buffer;
    buffer.fill(0.0);
    Point coordinates;
    coordinates.fill(0.0);
    std::uint64_t ndim = p_poly_shr->ndim();
    // evaluate for each point
    for (std::uint64_t i_point = thread_idx; i_point < n_points; i_point += block_size) {
        const double * point = point_data + i_point * ndim;
        std::copy_n(point, ndim, coordinates.begin());
        p_result[i_point] = p_poly->eval(coordinates, buffer);
    }
    __syncthreads();
}

// Evaluate regression by GPU
void regpl::eval_by_gpu(const regpl::Polynomial * p_poly, const double * point_data, double * p_result,
                        std::uint64_t n_points, std::uint64_t shared_mem_size, std::uint64_t n_threads,
                        const cuda::Stream & stream) noexcept {
    ::cudaStream_t cuda_stream = reinterpret_cast<::cudaStream_t>(stream.get_stream_ptr());
    eval_kernel<<<1, n_threads, shared_mem_size, cuda_stream>>>(p_poly, point_data, p_result, n_points);
}

}  // namespace merlin
