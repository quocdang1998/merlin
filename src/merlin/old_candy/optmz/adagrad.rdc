// Copyright 2023 quocdang1998
#include "merlin/candy/optmz/adagrad.hpp"

#include <cstdio>

#include "merlin/candy/model.hpp"  // merlin::candy::Model

namespace merlin {

// ---------------------------------------------------------------------------------------------------------------------
// AdaGrad
// ---------------------------------------------------------------------------------------------------------------------

#ifdef __NVCC__

// Erase train history GPU
__cudevice__ void candy::optmz::AdaGrad::erase_history_gpu(std::uint64_t thread_idx,
                                                           std::uint64_t block_size) noexcept {
    std::uint64_t size = this->grad_history_.size();
    for (std::uint64_t i_param = thread_idx; i_param < size; i_param += block_size) {
        this->grad_history_[i_param] = 0.0;
    }
}

// Update model by gradient value of current thread
__cudevice__ void candy::optmz::AdaGrad::update_gpu(candy::Model * p_model, floatvec * p_gradient, void * share_ptr,
                                                    std::uint64_t thread_idx, std::uint64_t block_size) noexcept {
    // get data from share memory
    double & learning_rate = *(reinterpret_cast<double *>(share_ptr));
    double & bias = *(&learning_rate + 1);
    double *& grad_history_data = *(reinterpret_cast<double **>(&bias + 1));
    // loop over each parameter
    for (std::uint64_t i_param = thread_idx; i_param < p_gradient->size(); i_param += block_size) {
        // update gradient norm
        double new_gradient_norm = grad_history_data[i_param];
        new_gradient_norm += (*p_gradient)[i_param] * (*p_gradient)[i_param];
        // update parameter
        double & param_value = (*p_model)[i_param];
        double correction = learning_rate * (*p_gradient)[i_param];
        correction /= std::sqrt(new_gradient_norm + bias_);
        param_value -= correction;
        // save new norm
        grad_history_data[i_param] = new_gradient_norm;
    }
    __syncthreads();
}

// Copy data to a pre-allocated memory region by a GPU block of threads
__cudevice__ void * candy::optmz::AdaGrad::copy_data_by_block(void * data_ptr, std::uint64_t thread_idx,
                                                              std::uint64_t block_size) {
    double * learning_rate_data = reinterpret_cast<double *>(data_ptr);
    double * bias_data = learning_rate_data + 1;
    double ** grad_history_data = reinterpret_cast<double **>(bias_data + 1);
    if (thread_idx == 0) {
        *learning_rate_data = this->learning_rate_;
        *bias_data = this->bias_;
        *grad_history_data = this->grad_history_.data();
    }
    __syncthreads();
    return reinterpret_cast<void *>(grad_history_data + 1);
}

// Copy data to a pre-allocated memory region by a single GPU threads
__cudevice__ void * candy::optmz::AdaGrad::copy_data_by_thread(void * data_ptr) {
    double * learning_rate_data = reinterpret_cast<double *>(data_ptr);
    double * bias_data = learning_rate_data + 1;
    double ** grad_history_data = reinterpret_cast<double **>(bias_data + 1);
    *learning_rate_data = this->learning_rate_;
    *bias_data = this->bias_;
    *grad_history_data = this->grad_history_.data();
    return reinterpret_cast<void *>(grad_history_data + 1);
}

#endif  // __NVCC__

}  // namespace merlin
