// Copyright 2023 quocdang1998
#include "merlin/candy/launcher.hpp"

#include <utility>  // std::move

#include "merlin/array/parcel.hpp"  // merlin::array::Parcel
#include "merlin/candy/model.hpp"  // merlin::candy::Model
#include "merlin/candy/optimizer.hpp"  // merlin::candy::Optimizer
#include "merlin/cuda/memory.hpp"  // merlin::cuda::copy_class_to_shared_mem

namespace merlin {

// Update gradient kernel
__global__ static void update_gradient_kernel(candy::Model * p_model, const array::Parcel * p_train_data,
                                              candy::Optimizer * p_optimizer, double * p_gradient,
                                              std::uint64_t model_size, std::uint64_t rep) {
    // get thread ID and block size
    std::uint64_t n_threads = size_of_block(), thread_idx = flatten_thread_index();
    // copy to shared memory
    extern __shared__ char share_ptr[];
    auto shared_mem_tuple = cuda::copy_class_to_shared_mem(share_ptr, *p_model, *p_train_data, *p_optimizer);
    
}

// Launch asynchronously model fitting algorithm on GPU
void candy::gpu_async_launch(candy::Model * p_model, const array::Parcel * p_train_data,
                             candy::Optimizer * p_optimizer, double * p_gradient, std::uint64_t model_size,
                             std::uint64_t rep, std::uint64_t shared_mem_size, std::uintptr_t stream_ptr,
                             std::uint64_t n_thread) {
    ::cudaStream_t cuda_stream = reinterpret_cast<::cudaStream_t>(stream_ptr);
    update_gradient_kernel<<<1, n_thread, shared_mem_size, cuda_stream>>>(p_model, p_train_data, p_optimizer,
                                                                          p_gradient, model_size, rep);
}

}  // namespace merlin
