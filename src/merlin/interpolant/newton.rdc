// Copyright 2022 quocdang1998
#include "merlin/interpolant/newton.hpp"

#include "merlin/array/parcel.hpp"  // merlin::array::Parcel
#include "merlin/interpolant/cartesian_grid.hpp"  // merlin::interpolant::CartesianGrid
#include "merlin/utils.hpp"  // merlin::prod_elements, merlin::contiguous_to_ndim_idx

namespace merlin {

// Concatenate 3 intvec
__cuhostdev__ static intvec merge_3vectors(const intvec & v1, const intvec & v2, const intvec & v3) {
    intvec result(v1.size() + v2.size() + v3.size());
    for (std::uint64_t i = 0; i < v1.size(); i++) {
        result[i] = v1[i];
    }
    for (std::uint64_t i = 0; i < v2.size(); i++) {
        result[v1.size()+i] = v2[i];
    }
    for (std::uint64_t i = 0; i < v3.size(); i++) {
        result[v2.size()+v1.size()+i] = v3[i];
    }
    return result;
}

// Calculate Newton coefficients by a signle CPU or GPU core
__cuhostdev__ void interpolant::calc_newton_coeffs_single_core(const interpolant::CartesianGrid & grid,
                                                               array::NdData & coeff) {
    // dynamic cast
    #ifdef __CUDA_ARCH__
    array::Parcel * p_coeff = static_cast<array::Parcel *>(&coeff);
    #else
    array::Array * p_coeff = static_cast<array::Array *>(&coeff);
    #endif  // __CUDA_ARCH__
    // loop on each dimension
    for (std::uint64_t i_dim = 0; i_dim < coeff.ndim(); i_dim++) {
        // get grid vector at current diemnsion
        const Vector<double> & grid_vector = grid.grid_vectors()[grid.ndim() - coeff.ndim() + i_dim];
        // get shape and size of previous dimensions
        intvec shape_previous_dims;
        shape_previous_dims.assign(const_cast<std::uint64_t *>(coeff.shape().begin()), i_dim);
        std::uint64_t size_previous_dims = prod_elements(shape_previous_dims);
        // get shape and size of divdiff subspace
        intvec shape_divdiff_space;
        shape_divdiff_space.assign(const_cast<std::uint64_t *>(coeff.shape().begin())+i_dim+1,
                                   const_cast<std::uint64_t *>(coeff.shape().end()));
        std::uint64_t size_divdiff_space = prod_elements(shape_divdiff_space);
        // loop on each previous dims point
        #ifndef __CUDA_ARCH__
        #pragma omp parallel for collapse(1) schedule(guided, Environment::parallel_chunk)
        #endif  // !__CUDA_ARCH__
        for (std::int64_t i_previous_dims = 0; i_previous_dims < size_previous_dims; i_previous_dims++) {
            intvec index_previous_dims = contiguous_to_ndim_idx(i_previous_dims, shape_previous_dims);
            // loop on indices of current dim for divide difference
            for (std::uint64_t i = 1; i < coeff.shape()[i_dim]; i++) {
                for (std::uint64_t k = coeff.shape()[i_dim]-1; k >= i; k--) {
                    // loop on each point in divdiff space
                    for (std::uint64_t i_divdiff_space = 0; i_divdiff_space < size_divdiff_space; i_divdiff_space++) {
                        intvec index_divdiff_space = contiguous_to_ndim_idx(i_divdiff_space, shape_divdiff_space);
                        intvec point_index_k = merge_3vectors(index_previous_dims, {k}, index_divdiff_space);
                        intvec point_index_k_1 = merge_3vectors(index_previous_dims, {k-1}, index_divdiff_space);
                        double divdiff_result = ((*p_coeff)[point_index_k] - (*p_coeff)[point_index_k_1]);
                        divdiff_result /= grid_vector[k] - grid_vector[k-i];
                        intvec point_index_result = std::move(point_index_k);
                        (*p_coeff)[point_index_result] = divdiff_result;
                    }
                }
            }
        }
    }
}

}  // namespace merlin
