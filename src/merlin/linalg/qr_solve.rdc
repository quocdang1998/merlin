// Copyright 2023 quocdang1998
#include "merlin/linalg/qr_solve.hpp"

#include <cmath>  // std::copysign, std::sqrt

#include "merlin/linalg/matrix.hpp"  // merlin::linalg::Matrix

namespace merlin {

// ---------------------------------------------------------------------------------------------------------------------
// Matrix inversion by QR decomposition
// ---------------------------------------------------------------------------------------------------------------------

// Perform Householder reflection on a matrix
__cuhostdev__ void linalg::householder_reflect(linalg::Matrix & M, const floatvec & v, std::uint64_t start_dimension,
                                               std::uint64_t thread_idx, std::uint64_t nthreads) noexcept {
    // apply Householder transformation to each matrix column
    // std::printf("start_dimension = %I64u, n_col = %I64u, nthreads = %I64u\n", start_dimension, M.ncol(), nthreads);
    for (std::uint64_t i_col = thread_idx; i_col < M.ncol(); i_col += nthreads) {
        // calculate inner product with column vector
        double column_inner_prod = 0.0;
        for (std::uint64_t i_row = start_dimension; i_row < M.nrow(); i_row++) {
            column_inner_prod += M.get(i_row, i_col) * v[i_row];
        }
        // std::printf("column_inner_prod = %f\n", column_inner_prod);
        column_inner_prod *= 2.f;
        // substract by 2*<col*v>*v_i
        for (std::uint64_t i_row = start_dimension; i_row < M.nrow(); i_row++) {
            M.get(i_row, i_col) -= column_inner_prod * v[i_row];
        }
    }
}

// Solve upper right linear system
__cuhostdev__ void linalg::upright_solver(const linalg::Matrix & R, linalg::Matrix & B, std::uint64_t thread_idx,
                                          std::uint64_t nthreads) noexcept {
    // parallel solve for each column of B
    for (std::uint64_t i_col = thread_idx; i_col < B.ncol(); i_col++) {
        for (std::int64_t i_row = B.nrow() - 1; i_row >= 0; i_row--) {
            // solve for the value of i_row
            const double & diagonal_element = R.cget(i_row, i_row);
            B.get(i_row, i_col) /= diagonal_element;
            // subtract each previous rows by coeff * B[i_row, i_col]
            for (std::uint64_t i_previous = 0; i_previous < i_row; i_previous++) {
                const double & off_diagonal = R.cget(i_previous, i_row);
                B.get(i_previous, i_col) -= off_diagonal * B.get(i_row, i_col);
            }
        }
    }
}

#ifdef __NVCC__

// QR decomposition by GPU parallelism
__cudevice__ void linalg::qr_decomposition_gpu(linalg::Matrix & M, linalg::Matrix & B, double * buffer, double & norm,
                                               std::uint64_t thread_idx, std::uint64_t nthreads) noexcept {
    // initialize temporary memory for refectant vector
    floatvec reflect_vector;
    reflect_vector.assign(buffer, M.nrow());
    std::uint64_t dim_max = M.nrow() - 1;
    // recursively call for each dimension
    for (std::uint64_t i_dim = 0; i_dim < dim_max; i_dim++) {
        // get the norm of the first column vector of the sub matrix
        double thread_norm = 0.0;
        if (thread_idx == 0) {
            norm = 0.0;
        }
        __syncthreads();
        for (std::uint64_t i_row = i_dim + thread_idx; i_row < M.nrow(); i_row += nthreads) {
            double & element = M.get(i_row, i_dim);
            thread_norm += element * element;
        }
        ::atomicAdd_block(&norm, thread_norm);
        __syncthreads();
        if (thread_idx == 0) {
            norm = std::sqrt(norm);
        }
        __syncthreads();
        // calculate v = (matrix[:,i_dim] - norm * e_idim) / norm(v)
        for (std::uint64_t i_row = i_dim + thread_idx; i_row < M.nrow(); i_row += nthreads) {
            reflect_vector[i_row] = M.get(i_row, i_dim);
            reflect_vector[i_row] += (i_row == i_dim) ? std::copysign(norm, reflect_vector[i_dim]) : 0.0;
        }
        __syncthreads();
        // normalize v
        if (thread_idx == 0) {
            norm = 0.0;
        }
        __syncthreads();
        thread_norm = 0.0;
        for (std::uint64_t i_row = i_dim + thread_idx; i_row < M.nrow(); i_row += nthreads) {
            thread_norm += reflect_vector[i_row] * reflect_vector[i_row];
        }
        ::atomicAdd_block(&norm, thread_norm);
        __syncthreads();
        if (thread_idx == 0) {
            norm = std::sqrt(norm);
        }
        __syncthreads();
        for (std::uint64_t i_row = i_dim + thread_idx; i_row < M.nrow(); i_row += nthreads) {
            reflect_vector[i_row] /= norm;
        }
        __syncthreads();
        // perform Householder refection
        linalg::householder_reflect(M, reflect_vector, i_dim, thread_idx, nthreads);
        linalg::householder_reflect(B, reflect_vector, i_dim, thread_idx, nthreads);
        __syncthreads();
    }
}

// Solve linear system by QR decomposition
__cudevice__ void linalg::qr_solve_gpu(linalg::Matrix & M, linalg::Matrix & B, double * buffer, double & norm,
                                       std::uint64_t thread_idx, std::uint64_t nthreads) noexcept {
    linalg::qr_decomposition_gpu(M, B, buffer, norm, thread_idx, nthreads);
    linalg::upright_solver(M, B, thread_idx, nthreads);
}

#endif  // __NVCC__

}  // namespace merlin
